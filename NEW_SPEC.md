# TrueGul 서비스 기획서

## 1. 서비스 개요

### 1.1 서비스명
**TrueGul** (트루글)

### 1.2 서비스 정의
TOPIK(한국어능력시험) 쓰기 영역 학습자를 위한 AI 기반 채점 및 피드백 서비스

### 1.3 핵심 가치
- 실제 TOPIK 채점 기준에 기반한 객관적 평가
- 즉각적인 피드백으로 자기주도 학습 지원
- 수기/텍스트 입력 모두 지원하여 실전 환경 시뮬레이션

---

## 2. 타겟 사용자

### 2.1 주요 타겟
- TOPIK II (3~6급) 응시 준비생
- 한국 대학 입학/취업을 위해 TOPIK 고득점이 필요한 외국인
- 쓰기 영역 집중 학습이 필요한 중·고급 학습자

### 2.2 사용자 특성
| 항목 | 내용 |
|------|------|
| 국적 | 전 세계 (특정 국적 제한 없음) |
| 언어 | 영어 기반 UI (추후 확장 가능) |
| 학습 목표 | TOPIK II 쓰기 54번 고득점 |

---

## 3. 핵심 기능

### 3.1 답안 입력
| 입력 방식 | 설명 |
|----------|------|
| 텍스트 직접 입력 | 앱 내 텍스트 에디터 |
| 이미지 업로드 (v1) | 수기 답안 촬영 이미지 → OCR 변환 |

### 3.2 AI 채점
TOPIK 공식 채점 기준에 기반한 항목별 평가

| 채점 항목 | 배점 | 평가 내용 |
|----------|------|----------|
| 내용 및 과제 수행 | 20점 | 주제 적합성, 근거의 충실함 |
| 글의 전개 구조 | 15점 | 서론-본론-결론 구성, 문단 연결 |
| 언어 사용 | 15점 | 어휘 다양성, 문법 정확성, 표현의 적절성 |

### 3.3 피드백 제공
- 항목별 점수 및 총점
- 감점 요인 구체적 설명
- 개선을 위한 제안 (대안 표현, 구조 수정 등)
- 레벨별 목표 표현 달성 여부

### 3.4 AI 작성 감지
| 항목 | 내용 |
|------|------|
| 목적 | 사용자가 직접 작성했는지 검증 (부정행위 방지) |
| 기술 | **한국어 텍스트 학습 RoBERTa 모델** (기존 인프라 활용) |
| 처리 흐름 | 답안 제출 → AI 감지 → 채점 진행 |
| 결과 표시 | AI 의심 시 경고 라벨 표시 (채점은 계속 진행) |
| 데이터 저장 | Task DB에 감지 결과 저장 (추후 분석/기능 확장용) |

**저장 데이터**:
```json
{
  "ai_detection": {
    "score": 0.85,
    "is_flagged": true,
    "model_version": "roberta-ko-v1",
    "detected_at": "2026-01-09T12:00:00Z"
  }
}
```

**향후 확장 가능성**:
- AI 감지 통계 대시보드
- 반복 플래그 사용자 경고
- 학습 진정성 인증 배지

**통합 워크플로우**:
```
답안 제출 → AI 감지 (로컬, <1초) → LLM 채점 (API, ~20초)
                ↓
         AI 의심도 점수 반환
         (threshold 초과 시 경고)
         + Task DB에 결과 저장
```

### 3.5 다국어 지원
| 구분 | 지원 범위 |
|------|----------|
| UI 언어 | 사용자 선택 (영어 기본, 추후 확장) |
| 피드백 언어 | 사용자 설정으로 추가 언어 선택 가능 |

---

## 4. 제품 로드맵

### v0: MVP - LLM 기반 채점
**목표**: 핵심 가치 검증

| 기능 | 상세 |
|------|------|
| 대상 문항 | TOPIK II 54번 (600-700자 의견 제시형) |
| 입력 방식 | 텍스트 직접 입력만 |
| 채점 방식 | Few-shot prompting + Structured rubric |
| 출력 | 항목별 점수 + 피드백 (JSON 구조화) |

**Few-shot 데이터 구성**:
- 공식 모범답안 활용 (고득점 앵커)
- 합성 데이터 생성 (중간/저점수 예시)
  - 모범답안 의도적 열화 방식
  - 감점 요인별 예시 (구어체, 연결어 부재, 비문 등)

### v1: OCR 도입
**목표**: 실전 환경 지원

| 기능 | 상세 |
|------|------|
| 이미지 업로드 | 수기 답안 사진 |
| OCR 처리 | 한국어 손글씨 인식 |
| 후처리 | OCR 결과 검토/수정 UI |

### v2: 채점 고도화 + 데이터 축적
**목표**: 채점 정확도 향상 기반 마련

| 기능 | 상세 |
|------|------|
| 데이터 수집 | 사용자 답안 + AI 채점 결과 저장 |
| 사용자 피드백 | "도움이 됐나요?" 평가 수집 |
| 실제 점수 연동 | 시험 응시 후 실제 점수 입력 (선택) |
| 채점 구조화 | 항목별 세분화, 일관성 개선 |

**데이터 축적 스키마**:
```
- 사용자 원본 답안
- 문제 유형
- AI 채점 결과 (항목별 점수 + 피드백)
- 사용자 피드백 (유용성)
- (선택) 실제 TOPIK 점수
```

### v3: 모델 최적화
**목표**: 채점 정확도 및 일관성 극대화

| 옵션 | 조건 | 기대 효과 |
|------|------|----------|
| Fine-tuning | 채점 데이터 충분 시 | 미세한 점수 판단력 향상 |
| Calibration | 실제 점수 데이터 확보 시 | AI 점수 ↔ 실제 점수 보정 |
| RAG | 레벨별 표현 DB 방대해질 시 | 표현/문법 기준 정밀 매칭 |

### v4 이후: 확장
- 53번 문항 지원 (그래프/도표 설명)
- 51, 52번 문항 지원 (빈칸 채우기)
- TOPIK I 지원
- 학습 이력 기반 개인화 추천

---

## 5. 기술 아키텍처

### 5.1 시스템 구성도

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  Mobile App │────▶│  API Server │────▶│    Redis    │
│  (Flutter/  │     │   (Go/Gin)  │     │    Queue    │
│   React     │◀────│             │◀────│             │
│   Native)   │     │             │     │             │
└──────┬──────┘     └──────┬──────┘     └──────┬──────┘
       │                   │                   │
       │ Push              │                   ▼
       │ (FCM/APNs)        │            ┌─────────────┐
       │                   │            │  ML Server  │
       ▼                   ▼            │  (FastAPI)  │
┌─────────────┐     ┌─────────────┐     │             │
│    Push     │     │ PostgreSQL  │     │ ┌─────────┐ │
│  Service    │     │             │     │ │AI Detect│ │
│             │     │             │     │ │(RoBERTa)│ │
└─────────────┘     └─────────────┘     │ └─────────┘ │
                                        │ ┌─────────┐ │
       ┌─────────────┐                  │ │LLM API  │ │
       │     S3      │                  │ │(Claude/ │ │
       │  (이미지/   │◀─────────────────│ │ GPT)    │ │
       │   모델)     │                  │ └─────────┘ │
       └─────────────┘                  │ ┌─────────┐ │
                                        │ │OCR API  │ │
                                        │ │(v1)     │ │
                                        │ └─────────┘ │
                                        └─────────────┘
```

### 5.2 기술 스택

| 영역 | 기술 |
|------|------|
| Mobile App | Flutter 또는 React Native |
| API Server | Go/Gin (기존 인프라 유지) |
| ML Server | FastAPI/Python (기존 인프라 유지) |
| Message Queue | Redis (기존 인프라 유지) |
| ML/AI | LLM API (Claude/GPT) + AI 감지 (RoBERTa, 로컬) |
| OCR | 외부 API (Google Vision / Naver Clova OCR) |
| Storage | AWS S3 |
| Database | PostgreSQL (기존 인프라 유지) |
| Push Notification | FCM (Android) / APNs (iOS) |
| Deployment | AWS ECS Fargate |

### 5.3 주요 API 엔드포인트

| Method | Endpoint | 설명 |
|--------|----------|------|
| POST | `/submit/text` | 텍스트 답안 제출 |
| POST | `/submit/image` | 이미지 답안 제출 (v1) |
| GET | `/result/{id}` | 채점 결과 조회 |
| GET | `/history` | 제출 이력 조회 |

### 5.4 응답 처리 전략

**방식 비교**:

| 방식 | 구현 복잡도 | UX | 모바일 적합성 | 권장 |
|------|-----------|-----|--------------|------|
| 동기 처리 | 낮음 | ❌ 30초+ 대기 | ❌ 타임아웃 위험 | ❌ |
| 비동기 + 폴링 | 중간 | ⚠️ 반복 요청 | ⚠️ 배터리 소모 | ❌ |
| **비동기 + Push** | 중간 | ✅ 알림 수신 | ✅ 백그라운드 대기 | ✅ |
| 스트리밍 (SSE) | 높음 | ✅ 실시간 표시 | ⚠️ 연결 불안정 | △ |
| WebSocket | 높음 | ✅ 양방향 통신 | ⚠️ 연결 유지 필요 | ❌ |

**선택: 비동기 + Push Notification**

기존 인프라(Redis MQ + Callback)와 호환되며 모바일에 최적화

**처리 흐름**:
```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│  Mobile  │───▶│   API    │───▶│  Redis   │───▶│    ML    │
│   App    │    │  Server  │    │  Queue   │    │  Server  │
└──────────┘    └────┬─────┘    └──────────┘    └────┬─────┘
     ▲               │                               │
     │               │◀──────────────────────────────┘
     │               │         Callback (결과 저장)
     │               │
     └───────────────┴─── Push Notification (FCM/APNs)
```

**UX 시나리오: 백그라운드 처리**

사용자가 앱을 닫거나 다른 작업을 해도 채점이 진행됨

```
1. 답안 제출 → "채점 중입니다" 토스트 표시
2. 앱 백그라운드 전환 가능 (다른 앱 사용, 화면 끄기)
3. 채점 완료 시 Push 알림 수신
4. 알림 탭 → 앱 열림 → 결과 화면 표시
```

**상세 단계**:
1. 답안 제출 → API Server가 `submission_id` 즉시 반환
2. Redis Queue에 작업 등록 (기존 인프라)
3. ML Server 처리:
   - AI 감지 (로컬 RoBERTa, ~1초) → Task DB 저장
   - LLM 채점 (API 호출, ~15-25초)
4. Callback으로 결과 저장
5. Push 알림 발송 → 앱에서 결과 조회

**Push 실패 대응**:

| 실패 원인 | 대응 방안 |
|----------|----------|
| 알림 권한 거부 | 앱 내 "채점 결과" 탭에서 수동 조회 |
| 네트워크 불안정 | 앱 재시작 시 미확인 결과 배지 표시 |
| 토큰 만료 | 앱 실행 시 토큰 자동 갱신 |

**수동 조회 UX**:
```
[채점 기록] 탭 → 상태별 필터 (대기중/완료)
                  ↓
         미확인 결과에 "NEW" 배지 표시
         탭하면 결과 상세 화면으로 이동
```

**결과 보관 정책**:

| 항목 | 정책 |
|------|------|
| 보관 기간 | **무제한** (v0~v1) |
| 향후 확장 | 멤버십별 차등 적용 가능 (Free: 30일, Premium: 무제한 등) |
| 저장 데이터 | 원본 답안, 채점 결과, AI 감지 결과, 제출 시각 |

**대안 (v2 고려)**: 스트리밍 응답
- 채점 항목별로 순차 표시 (내용 → 구성 → 표현)
- 사용자 체감 대기 시간 감소
- SSE(Server-Sent Events) 활용

---

## 6. 비즈니스 모델

### 6.1 수익 구조

| 모델 | 내용 |
|------|------|
| 무료 체험 | 일일 N회 무료 채점 |
| 건당 과금 | 1회 채점당 $X |
| 구독 | 월 $Y로 무제한 채점 |

### 6.2 가격 책정 (예시)

| 플랜 | 가격 | 포함 내용 |
|------|------|----------|
| Free | $0 | 일 2회 채점 |
| Pay-per-use | $0.5/회 | 추가 채점 |
| Monthly | $9.99/월 | 무제한 채점 + 상세 분석 |
| Yearly | $79.99/년 | Monthly + 20% 할인 |

### 6.3 비용 구조 검증

**LLM API 비용 분석** (2024년 기준):

| 모델 | 입력 비용 | 출력 비용 | 예상 1회 비용 |
|------|----------|----------|--------------|
| GPT-4o | $2.50/1M | $10.00/1M | ~$0.03 |
| GPT-4o-mini | $0.15/1M | $0.60/1M | ~$0.002 |
| Claude 3.5 Sonnet | $3.00/1M | $15.00/1M | ~$0.04 |
| Claude 3.5 Haiku | $0.80/1M | $4.00/1M | ~$0.01 |

**1회 채점 토큰 추정**:
- 입력: 답안 (~700자 ≈ 500 tokens) + 프롬프트/Few-shot (~2000 tokens) = **~2,500 tokens**
- 출력: 항목별 피드백 JSON = **~800 tokens**

**수익성 분석** (Pay-per-use $0.5/회 기준):

| 모델 | API 비용 | 마진 | 마진율 |
|------|---------|------|--------|
| GPT-4o-mini | $0.002 | $0.498 | 99.6% |
| Claude 3.5 Haiku | $0.01 | $0.49 | 98% |
| GPT-4o | $0.03 | $0.47 | 94% |
| Claude 3.5 Sonnet | $0.04 | $0.46 | 92% |

**권장**: GPT-4o-mini 또는 Claude Haiku로 시작, 품질 검증 후 상위 모델 전환 검토

**OCR API 비용** (v1):

| 서비스 | 비용 | 비고 |
|--------|------|------|
| Google Vision | $1.50/1000건 | 한글 손글씨 지원 |
| Naver Clova OCR | 월 300건 무료, 이후 건당 과금 | 한글 특화 |

**월간 비용 시뮬레이션** (MAU 1,000, 평균 20회/월 채점):

| 항목 | 비용 |
|------|------|
| LLM API (20,000회 × $0.01) | $200 |
| OCR API (v1, 10% 이미지) | $3 |
| AWS 인프라 (ECS, RDS 등) | $150-300 |
| **월 총 비용** | **~$350-500** |

---

## 7. 데이터 전략

### 7.1 초기 데이터 (v0)

| 데이터 | 출처 | 용도 |
|--------|------|------|
| 공식 채점 기준 | TOPIK 홈페이지 | 루브릭 프롬프트 |
| 모범답안 | TOPIK 홈페이지 | 고득점 Few-shot 앵커 |
| 합성 답안 | 자체 생성 | 중간/저점수 Few-shot |

### 7.2 합성 데이터 생성 방법

**목적**: 점수대별 앵커 예시 확보

**생성 절차**:
1. 모범답안을 기준으로 의도적 열화
2. 감점 요인별 변형 적용
3. 점수대별 라벨링

**감점 요인 유형**:

| 영역 | 감점 요인 예시 |
|------|--------------|
| 내용 | 주제 이탈, 근거 부족, 예시 부적절 |
| 구성 | 서론/결론 부재, 문단 미구분, 논리 비약 |
| 표현 | 구어체 사용, 어휘 반복, 문법 오류, 연결어 부재 |

**점수대별 예시 수**:

| 점수대 | 예시 수 | 특징 |
|--------|--------|------|
| 고득점 (40-50) | 1개 | 공식 모범답안 |
| 중간 (25-35) | 2-3개 | 부분적 감점 요인 |
| 저점수 (10-20) | 2개 | 복합적 감점 요인 |

### 7.3 데이터 축적 계획 (v2~)

**수집 데이터**:
- 사용자 원본 답안
- AI 채점 결과
- 사용자 피드백 (유용성 평가)
- 실제 TOPIK 점수 (선택적 입력)

**활용 계획**:
- AI 채점 vs 실제 점수 상관관계 분석
- Fine-tuning 학습 데이터
- 채점 모델 calibration

---

## 8. 성공 지표

### 8.1 제품 지표

| 지표 | 목표 (v0) |
|------|----------|
| 채점 완료율 | 95% 이상 |
| 평균 응답 시간 | 30초 이내 |
| 피드백 유용성 평가 | 4.0/5.0 이상 |

### 8.2 비즈니스 지표

| 지표 | 목표 (출시 6개월) |
|------|------------------|
| MAU | 1,000+ |
| 유료 전환율 | 5% 이상 |
| 구독 유지율 | 월 80% 이상 |

---

## 9. 리스크 및 대응

| 리스크 | 대응 방안 |
|--------|----------|
| 채점 정확도 불신 | 채점 근거 투명하게 제시, 공식 기준 명시 |
| LLM 비용 증가 | 캐싱, 프롬프트 최적화, 필요시 Fine-tuned 모델 전환 |
| OCR 인식률 저조 (v1) | 사용자 수정 UI 제공, 점진적 개선 |
| 경쟁 서비스 출현 | 데이터 축적을 통한 채점 품질 차별화 |

---

## 10. 마일스톤

| 단계 | 주요 산출물 |
|------|-----------|
| Phase 1 | v0 개발 및 내부 테스트 |
| Phase 2 | 클로즈드 베타 (제한된 사용자) |
| Phase 3 | 퍼블릭 런칭 (v0) |
| Phase 4 | v1 OCR 도입 |
| Phase 5 | v2 데이터 축적 및 고도화 |

---

## 부록

### A. TOPIK II 54번 문항 특성

| 항목 | 내용 |
|------|------|
| 유형 | 의견 제시형 논술 |
| 분량 | 600-700자 |
| 배점 | 50점 |
| 시간 | 약 50분 권장 |
| 평가 요소 | 내용, 구성, 표현 |

### B. 공식 채점 기준 요약

**내용 및 과제 수행 (상/중/하)**:
- 상: 주제에 맞게 풍부한 내용 전개
- 중: 주제에 맞으나 내용이 다소 부족
- 하: 주제 이탈 또는 내용 빈약

**글의 전개 구조 (상/중/하)**:
- 상: 서론-본론-결론 명확, 논리적 연결
- 중: 구조는 있으나 연결이 다소 부자연스러움
- 하: 구조 불명확, 논리 비약

**언어 사용 (상/중/하)**:
- 상: 다양하고 적절한 어휘/문법, 고급 표현
- 중: 중급 수준 어휘/문법, 일부 오류
- 하: 제한적 어휘, 빈번한 문법 오류

---

*문서 버전: 1.2*
*최종 수정일: 2026년 1월 9일*

**변경 이력**:
- v1.2: AI 감지 한국어 모델 명시 및 DB 저장, 백그라운드 UX, Push 실패 대응, 결과 보관 정책 추가
- v1.1: 기술 스택 명확화, AI 감지 기능 추가, 비용 구조 검증, 응답 처리 전략 추가
- v1.0: 초안 작성